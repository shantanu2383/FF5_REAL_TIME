# -*- coding: utf-8 -*-
"""07/23 FF5 .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1beB84PC0SxWfKtJyR-dKPLPKNP6_FI3L
"""

import pandas as pd
import statsmodels.formula.api as smf
import numpy as np
import matplotlib.pyplot as plt

!pip install pandasql
import os
from datetime import datetime
from sklearn.model_selection import train_test_split
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error, mean_absolute_error

import math
import matplotlib.pyplot as plt
from datetime import datetime
import seaborn as sns
import pandasql as ps
from sqlite3 import connect
from google.colab import drive
drive.mount("/content/gdrive", force_remount=True)

conn=connect(':memory:')

#SET PATHS
main="/content/gdrive/MyDrive/FIMA SUMMER 2023/RISK MANAGEMENT/FAMA FRENCH FACTORS/main_"
raw= main + '_raw/'
aux= raw + 'Cake Shop Realtime Fundamentals as of June 23, 2023/'
clean= main + '_clean/'

#SET PATHS
main="/content/gdrive/MyDrive/FIMA SUMMER 2023/RISK MANAGEMENT/FAMA FRENCH FACTORS/_main/"
raw= main + '_raw/'
aux= raw + 'Cake Shop Realtime Fundamentals as of June 23, 2023/'
clean= main + '_clean/'

main_stocks_df=pd.read_csv(clean + "FF3 Dataload 07_17.csv")



"""# Construct Size Value Portfolios"""

#Create master copy of main stocks df and remove negative bm_values

main_stocks_df_master=main_stocks_df.copy()
main_stocks_df = main_stocks_df[main_stocks_df['bm_ratio'] >= 0]

from scipy.stats.mstats import winsorize
#winsorise returns at the 99.9% percentile
main_stocks_df['ret'] = winsorize(main_stocks_df['ret'], limits=[0.000, 0.001])

#Create portfolios based on size and value
valueWeightRet = main_stocks_df.groupby(['date', 'size_portfolio', 'value_portfolio']).apply(
    lambda x: np.average(pd.to_numeric(x['ret']), weights=pd.to_numeric(x['mkt_cap']))).reset_index()



valueWeightRet

valueWeightRet_pivot = valueWeightRet.pivot_table(index=['date'], columns=['size_portfolio', 'value_portfolio'], values=0)
valueWeightRet_pivot.reset_index(inplace=True)
# iterate over the columns and join them with a '/'
valueWeightRet_pivot.columns = ['/'.join(col) for col in valueWeightRet_pivot.columns.values]
p=valueWeightRet_pivot
p

#Construct Factors from Portfolios
p['smb__hml'] = 1/3*(p['S/H']+ p['S/M']+p['S/L']) - 1/3*(p['B/H']+p['B/L']+p['B/M'])
p['hml']=(0.5*(p['S/H']+p['B/H']))-(0.5*(p['S/L']+p['B/L']))

size_value=p

"""# Construct Size Investment Portfolios"""

main_stocks_df= main_stocks_df_master

main_stocks_df = main_stocks_df.dropna(subset=['mkt_cap', 'inv'])

main_stocks_df['ret'] = winsorize(main_stocks_df['ret'], limits=[0.000, 0.01])

valueWeightRet = main_stocks_df.groupby(['date', 'size_portfolio', 'inv_portfolio']).apply(
    lambda x: np.average(pd.to_numeric(x['ret']), weights=pd.to_numeric(x['mkt_cap']))).reset_index()

valueWeightRet

valueWeightRet_pivot = valueWeightRet.pivot_table(index=['date'], columns=['size_portfolio', 'inv_portfolio'], values=0)
valueWeightRet_pivot.reset_index(inplace=True)
# iterate over the columns and join them with a '/'
valueWeightRet_pivot.columns = ['/'.join(col) for col in valueWeightRet_pivot.columns.values]
p=valueWeightRet_pivot
p

p['cma']=0.5*(p['S/L']+p['B/L'])-0.5*(p['S/H']+p['B/H'])
p['smb__inv']=1/3*(p['S/H']+ p['S/M']+p['S/L']) - 1/3*(p['B/H']+p['B/L']+p['B/M'])

size_inv=p[['date/', 'cma', 'smb__inv']]

"""# Construct Size OP Portfolios"""

main_stocks_df=main_stocks_df_master

from scipy.stats.mstats import winsorize

main_stocks_df['ret'] = winsorize(main_stocks_df['ret'], limits=[0.000, 0.001])

valueWeightRet = main_stocks_df.groupby(['date', 'size_portfolio', 'op_portfolio']).apply(
    lambda x: np.average(pd.to_numeric(x['ret']), weights=pd.to_numeric(x['mkt_cap']))).reset_index()

valueWeightRet

valueWeightRet_pivot = valueWeightRet.pivot_table(index=['date'], columns=['size_portfolio', 'op_portfolio'], values=0)
valueWeightRet_pivot.reset_index(inplace=True)
# iterate over the columns and join them with a '/'
valueWeightRet_pivot.columns = ['/'.join(col) for col in valueWeightRet_pivot.columns.values]
p=valueWeightRet_pivot
p

p['rmw']=0.5*(p['S/H']+p['B/H'])-0.5*(p['S/L']+p['B/L'])
p['smb__op']=1/3*(p['S/H']+ p['S/M']+p['S/L']) - 1/3*(p['B/H']+p['B/L']+p['B/M'])

size_op=p[['date/', 'rmw', 'smb__op']]

"""# Merge Together Factors"""

factors= size_value.merge(size_inv, on='date/', how='outer')
factors= factors.merge(size_op, on='date/', how='outer')
factors

"""Calculate SMB Factor as average of 3 SMB Factors"""

factors['smb']=1/3*(factors['smb__hml']+factors['smb__inv']+factors['smb__op'])

"""Construct Market Factor"""

weighted_dailyRet=main_stocks_df.groupby('date').apply(lambda x: np.average(pd.to_numeric(x.ret), weights=pd.to_numeric(x.mkt_cap)))
mkt = pd.DataFrame(weighted_dailyRet)
mkt.reset_index(inplace=True)
mkt['date']=pd.to_datetime(mkt['date'])
mkt.rename(columns={0:'mkt'}, inplace=True)

mkt

factors

factors.rename(columns={'date/':'date'}, inplace=True)
factors['date']=pd.to_datetime(factors['date'])
factors = factors.merge(mkt, on='date', how='outer')
factors=factors[['date', 'mkt', 'smb', 'hml', 'cma', 'rmw']]

factors

"""# Import Fama French Data For Comparison"""

import pandas_datareader.data as web
from pandas_datareader.famafrench import get_available_datasets
datasets = get_available_datasets()



df_3_factor=[dataset for dataset in datasets if 'Research' in dataset and 'Factor' in dataset]
df_3_factor
ff=web.DataReader(df_3_factor[4],'famafrench',start='2018-01-01',end='2022-12-01')[0]
ff.reset_index(inplace=True)
ff

ff['Date']=pd.to_datetime(ff['Date'])
checker= factors.reset_index().merge(ff, left_on='date', right_on='Date', how='left')
checker

checker.corr(method='pearson').round(2)

import pandas as pd
import matplotlib.pyplot as plt


checker['date'] = pd.to_datetime(checker['date'])

# Plotting SMB vs smb
plt.figure(figsize=(10, 6))
plt.plot(checker['date'], checker['SMB'], label='Fama French Original SMB Factor')
plt.plot(checker['date'], checker['smb'], label='Reconcstruction of SMB Factor')
plt.xlabel('Date')
plt.ylabel('Value')
plt.title('Time Series :Fama French vs Reconstruction (SMB)')
plt.legend()
plt.show()

# Plotting HML vs hml
plt.figure(figsize=(10, 6))
plt.plot(checker['date'], checker['HML'], label='Fama French Original HML Factor')
plt.plot(checker['date'], checker['hml'], label='Reconstruction of HML Factor')
plt.xlabel('Date')
plt.ylabel('Value')
plt.title('Time Series :Fama French vs Reconstruction (HML)')
plt.legend()
plt.show()


# Plotting HML vs hml
plt.figure(figsize=(10, 6))
plt.plot(checker['date'], checker['CMA'], label='Fama French Original CMA Factor')
plt.plot(checker['date'], checker['cma'], label='Reconstruction of CMA Factor')
plt.xlabel('Date')
plt.ylabel('Value')
plt.title('Time Series :Fama French vs Reconstruction (CMA)')
plt.legend()
plt.show()

# Plotting HML vs hml
plt.figure(figsize=(10, 6))
plt.plot(checker['date'], checker['RMW'], label='Fama French Original RMW Factor')
plt.plot(checker['date'], checker['rmw'], label='Reconstruction of RMW Factor')
plt.xlabel('Date')
plt.ylabel('Value')
plt.title('Time Series :Fama French vs Reconstruction (RMW)')
plt.legend()
plt.show()

# Plotting HML vs hml
plt.figure(figsize=(10, 6))
plt.plot(checker['date'], checker['Mkt-RF'], label='Fama French Original MKT Factor')
plt.plot(checker['date'], checker['mkt'], label='Reconstruction of MKT Factor')
plt.xlabel('Date')
plt.ylabel('Value')
plt.title('Time Series :Fama French vs Reconstruction (MKT)')
plt.legend()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

checker['date'] = pd.to_datetime(checker['date'])

# Function to calculate Pearson correlation coefficient
def pearson_corr(x, y):
    return x.corr(y)

# Plotting SMB vs smb
plt.figure(figsize=(10, 6))
plt.scatter(checker['SMB'], checker['smb'], label='SMB vs Reconstructed SMB', color='blue')
plt.xlabel('Fama French Original SMB Factor')
plt.ylabel('Reconstructed SMB Factor')
plt.title('Scatter Plot: Fama French vs Reconstruction (SMB)')
plt.axline([0, 0], slope=1, linestyle='--', color='red', label='Perfect Correlation')
plt.legend()
plt.show()

# Plotting HML vs hml
plt.figure(figsize=(10, 6))
plt.scatter(checker['HML'], checker['hml'], label='HML vs Reconstructed HML', color='orange')
plt.xlabel('Fama French Original HML Factor')
plt.ylabel('Reconstructed HML Factor')
plt.title('Scatter Plot: Fama French vs Reconstruction (HML)')
plt.axline([0, 0], slope=1, linestyle='--', color='red', label='Perfect Correlation')
plt.legend()
plt.show()

# Plotting CMA vs cma
plt.figure(figsize=(10, 6))
plt.scatter(checker['CMA'], checker['cma'], label='CMA vs Reconstructed CMA', color='green')
plt.xlabel('Fama French Original CMA Factor')
plt.ylabel('Reconstructed CMA Factor')
plt.title('Scatter Plot: Fama French vs Reconstruction (CMA)')
plt.axline([0, 0], slope=1, linestyle='--', color='red', label='Perfect Correlation')
plt.legend()
plt.show()

# Plotting RMW vs rmw
plt.figure(figsize=(10, 6))
plt.scatter(checker['RMW'], checker['rmw'], label='RMW vs Reconstructed RMW', color='purple')
plt.xlabel('Fama French Original RMW Factor')
plt.ylabel('Reconstructed RMW Factor')
plt.title('Scatter Plot: Fama French vs Reconstruction (RMW)')
plt.axline([0, 0], slope=1, linestyle='--', color='red', label='Perfect Correlation')
plt.legend()
plt.show()

# Plotting Mkt-RF vs mkt
plt.figure(figsize=(10, 6))
plt.scatter(checker['Mkt-RF'], checker['mkt'], label='MKT vs Reconstructed MKT', color='cyan')
plt.xlabel('Fama French Original MKT Factor')
plt.ylabel('Reconstructed MKT Factor')
plt.title('Scatter Plot: Fama French vs Reconstruction (MKT)')
plt.axline([0, 0], slope=1, linestyle='--', color='red', label='Perfect Correlation')
plt.legend()
plt.show()